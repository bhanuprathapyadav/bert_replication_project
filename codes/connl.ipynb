# Install required dependencies
!pip install transformers datasets torch --quiet

# Import required libraries
from transformers import BertTokenizer, BertForTokenClassification
from datasets import load_dataset
import torch
import random

# Load the CoNLL-2003 dataset
conll_dataset = load_dataset("conll2003")

# Load the pre-trained BERT model and tokenizer for NER (fine-tuned on CoNLL-2003)
model_name = "dbmdz/bert-large-cased-finetuned-conll03-english"
model = BertForTokenClassification.from_pretrained(model_name)
tokenizer = BertTokenizer.from_pretrained(model_name)

# Set the device (use GPU if available)
device = 'cuda' if torch.cuda.is_available() else 'cpu'
model.to(device)

# Define a function to perform Named Entity Recognition (NER) on a given sentence
def perform_ner(sentence):
    # Tokenize the input sentence
    inputs = tokenizer(sentence, return_tensors="pt", truncation=True, padding=True, is_split_into_words=False)
    input_ids = inputs["input_ids"].to(device)

    # Perform inference (NER)
    with torch.no_grad():
        outputs = model(input_ids)
    logits = outputs.logits

    # Get the predicted token classification (entity types)
    predictions = torch.argmax(logits, dim=2)

    # Decode the tokens and predicted NER tags
    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])
    predicted_labels = [model.config.id2label[p.item()] for p in predictions[0]]

    # Combine subwords and labels, handling B/I entities correctly
    entities = []
    for token, label in zip(tokens, predicted_labels):
        if token.startswith("##"):
            # Combine subword with the previous word (remove '##' from subword)
            entities[-1] = (entities[-1][0] + token[2:], entities[-1][1])
        else:
            entities.append((token, label))
    return entities

# Randomly select an example from the CoNLL-2003 training set
random_index = random.randint(0, len(conll_dataset['train']) - 1)
example = conll_dataset['train'][random_index]
sentence = " ".join(example['tokens'])  # Join tokens to form the sentence

# Perform NER on the selected sentence
ner_results = perform_ner(sentence)

# Output the sentence and the NER results
print(f"Sentence: {sentence}")
print(f"NER Results:")
for token, label in ner_results:
    if label != "O":  # Only print tokens that have an entity label
        print(f"{token}: {label}")

