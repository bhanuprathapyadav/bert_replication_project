# Install required dependencies
!pip install transformers datasets torch --quiet

# Import required libraries
from transformers import BertTokenizer, BertForSequenceClassification
from datasets import load_dataset
import torch
import random

# Load the MNLI dataset (specifically the MNLI validation set)
mnli_dataset = load_dataset('glue', 'mnli')

# Load the pre-trained BERT model and tokenizer for MNLI
model_name = "textattack/bert-base-uncased-MNLI"
model = BertForSequenceClassification.from_pretrained(model_name)
tokenizer = BertTokenizer.from_pretrained(model_name)

# Set the device (use GPU if available)
device = 'cuda' if torch.cuda.is_available() else 'cpu'
model.to(device)

# Define a function to perform inference on a random MNLI example
def test_mnli_example(example):
    premise = example['premise']
    hypothesis = example['hypothesis']

    # Tokenize the inputs
    inputs = tokenizer(premise, hypothesis, return_tensors='pt', padding=True, truncation=True)

    # Move tensors to the correct device
    input_ids = inputs['input_ids'].to(device)
    attention_mask = inputs['attention_mask'].to(device)

    # Get model predictions
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
        logits = outputs.logits

    # Get predicted class (0: entailment, 1: neutral, 2: contradiction)
    predicted_class = torch.argmax(logits, dim=1).item()

    return premise, hypothesis, predicted_class

# Randomly select an example from the MNLI validation matched set
random_index = random.randint(0, len(mnli_dataset['validation_matched']) - 1)
example = mnli_dataset['validation_matched'][random_index]
premise, hypothesis, predicted_class = test_mnli_example(example)

# Class mapping
mnli_labels = ["entailment", "neutral", "contradiction"]
predicted_label = mnli_labels[predicted_class]

# Output the results
print(f"Premise: {premise}")
print(f"Hypothesis: {hypothesis}")
print(f"Predicted Class: {predicted_label}")

