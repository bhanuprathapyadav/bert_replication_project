# Install required dependencies
!pip install transformers datasets torch --quiet

# Import required libraries
from transformers import BertTokenizer, BertForTokenClassification
from datasets import Dataset
import torch
import json
import random
import numpy as np

# Load the custom NER dataset
with open("/datasets/conll_like_dataset_large.json", "r") as f:
    custom_ner_data = json.load(f)

# Initialize the tokenizer
model_name = "dbmdz/bert-large-cased-finetuned-conll03-english"
tokenizer = BertTokenizer.from_pretrained(model_name)

# Convert each example to tokens and labels
processed_data = {"tokens": [], "labels": []}
for example in custom_ner_data:
    sentence = example["sentence"]
    entity = example["entity"]
    entity_type = example["entity_type"]

    # Tokenize the sentence and the entity
    sentence_tokens = tokenizer.tokenize(sentence)
    labels = ["O"] * len(sentence_tokens)  # Initialize with "O" labels

    entity_tokens = tokenizer.tokenize(entity)
    entity_len = len(entity_tokens)

    # Assign labels for the entity tokens
    for i in range(len(sentence_tokens) - entity_len + 1):
        if sentence_tokens[i:i+entity_len] == entity_tokens:
            labels[i] = entity_type  # "B-ENTITY"
            for j in range(1, entity_len):
                labels[i + j] = "I-" + entity_type[2:]  # "I-ENTITY"
            break

    # Append to the processed data
    processed_data["tokens"].append(sentence_tokens)
    processed_data["labels"].append(labels)

# Convert to a Dataset object
custom_ner_dataset = Dataset.from_dict(processed_data)

# Load the pre-trained BERT model for NER
model = BertForTokenClassification.from_pretrained(model_name)
device = 'cuda' if torch.cuda.is_available() else 'cpu'
model.to(device)

# Define a function to perform NER on a given example
def perform_ner(example):
    tokens = example['tokens']
    labels = example['labels']

    # Tokenize and align labels with tokens
    inputs = tokenizer(tokens, is_split_into_words=True, return_tensors="pt", padding=True, truncation=True)
    input_ids = inputs["input_ids"].to(device)
    attention_mask = inputs["attention_mask"].to(device)

    # Perform inference (NER)
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits

    # Mask padding tokens and get predictions
    mask = attention_mask.bool()
    predicted_indices = torch.argmax(logits[mask], dim=1)
    predicted_labels = [model.config.id2label[idx.item()] for idx in predicted_indices]

    # Ensure all tokens are included, including 'O' labels
    all_tokens_labels = [(token, pred_label) for token, pred_label in zip(tokens, predicted_labels)]

    return tokens, predicted_labels, labels

# Randomly select an example from the custom dataset
random_index = random.randint(0, len(custom_ner_dataset) - 1)
example = custom_ner_dataset[random_index]

# Perform NER on the selected example
tokens, predicted_labels, true_labels = perform_ner(example)

# Output the results
print("Tokens: ", tokens)
print("Predicted Labels: ", predicted_labels)
print("True Labels: ", true_labels)

